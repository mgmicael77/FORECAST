{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This code is an implementation of a **time series forecasting model using XGBoost**, a popular gradient boosting algorithm. The model is trained on a dataset of unit sales data for a number of unique items and stores, and the goal is to predict future unit sales for each unique item-store combination.\n\nThe code begins by reading in the dataset and performing some preprocessing steps, including adding a unique ID column, dropping irrelevant columns, and one-hot encoding the category column. It then splits the data into training and test sets for each unique item-store combination and performs cross-validation on the training data using a TimeSeriesSplit.\n\nThe XGBoost model is then trained on the training data for each unique item-store combination, and the model is used to make predictions for the next day's unit sales using a sliding window approach. The predictions are stored in a dataframe along with the actual values, and the results are plotted for each unique item-store combination.\n\nOverall, the code implements a robust and flexible time series forecasting model that can be easily adapted to other datasets and forecasting problems.","metadata":{"papermill":{"duration":0.009259,"end_time":"2023-05-11T11:50:56.759934","exception":false,"start_time":"2023-05-11T11:50:56.750675","status":"completed"},"tags":[]}},{"cell_type":"code","source":"pip install xgboost","metadata":{"papermill":{"duration":12.327798,"end_time":"2023-05-11T11:51:09.094863","exception":false,"start_time":"2023-05-11T11:50:56.767065","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-25T14:53:33.672463Z","iopub.execute_input":"2023-05-25T14:53:33.673427Z","iopub.status.idle":"2023-05-25T14:53:49.016486Z","shell.execute_reply.started":"2023-05-25T14:53:33.673378Z","shell.execute_reply":"2023-05-25T14:53:49.014971Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: xgboost in /opt/conda/lib/python3.10/site-packages (1.7.5)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from xgboost) (1.23.5)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from xgboost) (1.9.3)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport random\nfrom sklearn.preprocessing import LabelEncoder\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom math import sqrt\nfrom sklearn.model_selection import TimeSeriesSplit\nimport matplotlib.pyplot as plt\nimport xgboost as xgb\n\n# Define the path to 'total.csv'\n#total_csv_path = '/kaggle/input/total-final/total.csv'\ntotal_csv_path = '/kaggle/input/total-with-category/total_with_category.csv'\n\n# Load 'total.csv' and set index to 'date'\n#data = pd.read_csv(total_csv_path, parse_dates=['date'], index_col='date')\ndata = pd.read_csv(total_csv_path)\ndata = data[data['store'] == 548]\n\n# Add 'unique_id' column\n#data['unique_id'] = data['item_nbr'].astype(str) + '_' + data['store'].astype(str)\ndata['unique_id'] = data['item_nbr'].astype(int) \n\n# Drop 'item_nbr' and 'store' columns\ndata.drop(['item_nbr', 'store'], axis=1, inplace=True)\n\n# Select 1 random unique_ids and filter the data\nrandom_unique_ids = random.sample(list(data['unique_id'].unique()), 5)\n#random_unique_ids = data['unique_id'].unique()\ndata = data[data['unique_id'].isin(random_unique_ids)]\n\n#data = data.drop('index', axis=1)\n# Sort the data by 'unique_id' and 'date'\ndata.sort_values(by=['unique_id', 'date'], inplace=True)\n\n# Convert the date column to a datetime object and set it as the index\ndata['date'] = pd.to_datetime(data['date'])\ndata.set_index('date', inplace=True)\n                        \n# Assuming the data is already loaded into the DataFrame 'data'\ndata['category'] = data['category'].fillna('undefined')\n\n# One-hot encoding for the 'category' column if there are more categories\ndata = pd.get_dummies(data, columns=['category'])\n\n\n# Sort the data by 'unique_id' and 'date'\ndata.sort_values(by=['unique_id', 'date'], inplace=True)\n\n# Add lags for the past 7 days\nfor i in range(1, 8):\n    data[f'unit_sales_lag_{i}'] = data.groupby('unique_id')['unit_sales'].shift(i)\n\ndata = data.dropna()\n\ndata","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":24.632202,"end_time":"2023-05-11T11:51:33.734572","exception":false,"start_time":"2023-05-11T11:51:09.102370","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-25T14:53:49.019719Z","iopub.execute_input":"2023-05-25T14:53:49.020199Z","iopub.status.idle":"2023-05-25T14:53:50.832101Z","shell.execute_reply.started":"2023-05-25T14:53:49.020150Z","shell.execute_reply":"2023-05-25T14:53:50.827690Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 19\u001b[0m\n\u001b[1;32m     15\u001b[0m total_csv_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshop_cat.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Load 'total.csv' and set index to 'date'\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#data = pd.read_csv(total_csv_path, parse_dates=['date'], index_col='date')\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_csv_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m data \u001b[38;5;241m=\u001b[39m data[data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m548\u001b[39m]\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Add 'unique_id' column\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#data['unique_id'] = data['item_nbr'].astype(str) + '_' + data['store'].astype(str)\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'shop_cat.csv'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'shop_cat.csv'","output_type":"error"}]},{"cell_type":"markdown","source":"**Cross-validation** is a technique used to evaluate the performance of a machine learning model by training and testing it on different subsets of the data. In this case, the TimeSeriesSplit class is used to split the time series data into multiple folds to evaluate the model's performance over time.","metadata":{"papermill":{"duration":0.007782,"end_time":"2023-05-11T11:51:33.750856","exception":false,"start_time":"2023-05-11T11:51:33.743074","status":"completed"},"tags":[]}},{"cell_type":"code","source":"train_ratio = 0.8\n\n# Create a dictionary to store train and test data for each unique_id\ntrain_test_data = {}\n\nfor i, unique_id in enumerate(random_unique_ids):\n    unique_id_data = data[data['unique_id'] == unique_id]\n    train_size = int(len(unique_id_data) * train_ratio)\n    train = unique_id_data.iloc[:train_size]\n    test = unique_id_data.iloc[train_size:]\n\n    # Perform cross-validation on the train set\n    train = train.sort_index()\n\n    tss = TimeSeriesSplit(n_splits=5, test_size=100, gap=1)\n\n    # Create a list to store train and test folds for each unique_id\n    train_test_folds = []\n    for train_idx, val_idx in tss.split(train):\n        train_fold = train.iloc[train_idx]\n        test_fold = train.iloc[val_idx]\n        train_test_folds.append((train_fold, test_fold))\n\n    # Store train and test data in the dictionary\n    train_test_data[unique_id] = {'train': train, 'test': test, 'folds': train_test_folds}\n","metadata":{"papermill":{"duration":0.034452,"end_time":"2023-05-11T11:51:33.792694","exception":false,"start_time":"2023-05-11T11:51:33.758242","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-25T14:53:50.838110Z","iopub.status.idle":"2023-05-25T14:53:50.838738Z","shell.execute_reply.started":"2023-05-25T14:53:50.838416Z","shell.execute_reply":"2023-05-25T14:53:50.838445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train","metadata":{"papermill":{"duration":0.007151,"end_time":"2023-05-11T11:51:33.807532","exception":false,"start_time":"2023-05-11T11:51:33.800381","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Concatenate train sets from all unique_ids\nall_train_data = pd.concat([train_test_data[unique_id]['train'] for unique_id in random_unique_ids])\n\nall_train_data = all_train_data.sort_index()\n\n# Create a TimeSeriesSplit object\ntss = TimeSeriesSplit(n_splits=5, test_size=100, gap=1)\n\nfold = 0\npreds = []\nscores = []\nfor train_idx, val_idx in tss.split(all_train_data):\n    train_fold = all_train_data.iloc[train_idx]\n    val_fold = all_train_data.iloc[val_idx]\n\n    #FEATURES = ['unique_id','bogo', 'circular_discount', 'circular', 'circedlp', 'coupon', 'discount_value', 'discount', 'fp_discount', 'front_page', 'fpedlp', 'gas', 'nopromo', 'category_DAIRY', 'category_DELI', 'category_FROZEN', 'category_GENERAL MERCH', 'category_GROCERY', 'category_HBC', 'category_MEAT', 'category_PRODUCE', 'category_undefined']\n    FEATURES = ['unique_id','bogo', 'circular_discount', 'circular', 'circedlp', 'coupon', 'discount_value', 'discount', 'fp_discount', 'front_page', 'fpedlp', 'gas', 'nopromo', 'category_DAIRY', 'category_FROZEN','category_GROCERY', 'category_HBC', 'category_MEAT', 'category_PRODUCE', 'category_undefined']\n    #,\"unit_sales_lag_8\",\"unit_sales_lag_9\",\"unit_sales_lag_10\",\"unit_sales_lag_11\",\"unit_sales_lag_12\",\"unit_sales_lag_13\",\"unit_sales_lag_14\"\n    TARGET = 'unit_sales'\n\n    X_train = train_fold[FEATURES]\n    y_train = train_fold[TARGET]\n\n    X_val = val_fold[FEATURES]\n    y_val = val_fold[TARGET]\n\n    reg = xgb.XGBRegressor(base_score=0.5, booster='gbtree',\n                           n_estimators=1000,\n                           early_stopping_rounds=50,\n                           objective='reg:squarederror',\n                           max_depth=3,\n                           learning_rate=0.01)\n    reg.fit(X_train, y_train,\n            eval_set=[(X_train, y_train), (X_val, y_val)],\n            verbose=100)\n\n    y_pred = reg.predict(X_val)\n    preds.append(y_pred)\n    score = np.sqrt(mean_squared_error(y_val, y_pred))\n    scores.append(score)\n","metadata":{"papermill":{"duration":3.068862,"end_time":"2023-05-11T11:51:36.883931","exception":false,"start_time":"2023-05-11T11:51:33.815069","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-25T14:53:50.840595Z","iopub.status.idle":"2023-05-25T14:53:50.841202Z","shell.execute_reply.started":"2023-05-25T14:53:50.840902Z","shell.execute_reply":"2023-05-25T14:53:50.840929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Mean score across folds: {np.mean(scores):.4f}')\nprint(f'Fold scores: {scores}')","metadata":{"papermill":{"duration":0.018597,"end_time":"2023-05-11T11:51:36.914118","exception":false,"start_time":"2023-05-11T11:51:36.895521","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-25T14:53:50.842689Z","iopub.status.idle":"2023-05-25T14:53:50.843235Z","shell.execute_reply.started":"2023-05-25T14:53:50.842955Z","shell.execute_reply":"2023-05-25T14:53:50.842986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#FEATURES = ['unique_id','bogo', 'circular_discount', 'circular', 'circedlp', 'coupon', 'discount_value', 'discount', 'fp_discount', 'front_page', 'fpedlp', 'gas', 'nopromo', 'category_DAIRY', 'category_DELI', 'category_FROZEN', 'category_GENERAL MERCH', 'category_GROCERY', 'category_HBC', 'category_MEAT', 'category_PRODUCE', 'category_undefined',\"unit_sales_lag_1\",\"unit_sales_lag_2\",\"unit_sales_lag_3\",\"unit_sales_lag_4\",\"unit_sales_lag_5\",\"unit_sales_lag_6\",\"unit_sales_lag_7\"]\nFEATURES = ['unique_id','bogo', 'circular_discount', 'circular', 'circedlp', 'coupon', 'discount_value', 'discount', 'fp_discount', 'front_page', 'fpedlp', 'gas', 'nopromo', 'category_DAIRY', 'category_FROZEN', 'category_GROCERY', 'category_HBC', 'category_MEAT', 'category_PRODUCE', 'category_undefined']\nTARGET = 'unit_sales'\n\nX_all = all_train_data[FEATURES]\ny_all = all_train_data[TARGET]\n\nreg = xgb.XGBRegressor(base_score=0.5,\n                       booster='gbtree',\n                       n_estimators=500,\n                       objective='reg:squarederror',\n                       max_depth=20,\n                       learning_rate=0.01)\nreg.fit(X_all, y_all,\n        eval_set=[(X_all, y_all)],\n        verbose=100)\n","metadata":{"papermill":{"duration":1.64494,"end_time":"2023-05-11T11:51:38.568257","exception":false,"start_time":"2023-05-11T11:51:36.923317","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-25T14:53:50.844900Z","iopub.status.idle":"2023-05-25T14:53:50.845426Z","shell.execute_reply.started":"2023-05-25T14:53:50.845153Z","shell.execute_reply":"2023-05-25T14:53:50.845178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test","metadata":{"papermill":{"duration":0.010033,"end_time":"2023-05-11T11:51:38.588673","exception":false,"start_time":"2023-05-11T11:51:38.578640","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from joblib import Parallel, delayed\nfrom tqdm import tqdm\n\n# Set the window size and horizon\nwindow_size = 14\nhorizon = 1\n\n# Define a function for each iteration\ndef make_prediction(unique_id, train_test_data, reg, FEATURES, TARGET, window_size):\n    test_unique_id = train_test_data[unique_id]['test']\n    preds = []\n\n    # Iterate through the test set using the sliding window method\n    for i in range(0, len(test_unique_id) - window_size - horizon + 1):\n        # Select the window from the test set\n        window = test_unique_id.iloc[i:i+window_size]\n\n        # Prepare the features and target for the window\n        X_window = window[FEATURES]\n        y_window = window[TARGET]\n\n        # Fit the model on the window\n        reg.fit(X_window, y_window,\n                eval_set=[(X_window, y_window)],\n                verbose=False)\n\n        # Make a prediction for the next day\n        X_next_day = test_unique_id[FEATURES].iloc[i+window_size]\n        y_next_day = test_unique_id[TARGET].iloc[i+window_size]\n        y_pred = reg.predict(np.array(X_next_day).reshape(1, -1))\n\n        preds.append({\n            'unique_id': test_unique_id['unique_id'].iloc[i+window_size],\n            'date': test_unique_id.index[i+window_size],\n            'actuals': y_next_day,\n            'predicted': y_pred[0]\n        })\n\n    return preds\n\n# Use joblib and tqdm to parallelize and show the progress bar\npredictions = Parallel(n_jobs=-1)(\n    delayed(make_prediction)(unique_id, train_test_data, reg, FEATURES, TARGET, window_size)\n    for unique_id in tqdm(random_unique_ids)\n)\n\n# Prepare an empty DataFrame to store the predictions\npredictions_df = pd.DataFrame(columns=['unique_id', 'date', 'actuals', 'predicted'])\n\n# Concatenate the results\nfor preds in predictions:\n    predictions_df = pd.concat([predictions_df, pd.DataFrame(preds, columns=predictions_df.columns)], ignore_index=True)\n\n","metadata":{"papermill":{"duration":94.508161,"end_time":"2023-05-11T11:53:13.106928","exception":false,"start_time":"2023-05-11T11:51:38.598767","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-25T14:53:50.847186Z","iopub.status.idle":"2023-05-25T14:53:50.847738Z","shell.execute_reply.started":"2023-05-25T14:53:50.847453Z","shell.execute_reply":"2023-05-25T14:53:50.847476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display the predictions DataFrame\npredictions_df['predicted'] = np.round(predictions_df['predicted'])\npredictions_df","metadata":{"papermill":{"duration":0.066921,"end_time":"2023-05-11T11:53:13.223570","exception":false,"start_time":"2023-05-11T11:53:13.156649","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-25T14:53:50.849246Z","iopub.status.idle":"2023-05-25T14:53:50.849817Z","shell.execute_reply.started":"2023-05-25T14:53:50.849524Z","shell.execute_reply":"2023-05-25T14:53:50.849547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Loop through each unique_id in the test set\nfor unique_id in random_unique_ids:\n    # Filter the data for the current unique_id\n    train_filtered = train_test_data[unique_id]['train']\n    test_filtered = train_test_data[unique_id]['test']\n    results_filtered = predictions_df[predictions_df['unique_id'] == unique_id]\n\n    # Extract the unit sales values for the current unique_id\n    Y_train_filtered = train_filtered[TARGET].values\n    Y_test_filtered = test_filtered[TARGET].values\n\n    # Get the predicted values directly from the 'results_filtered' DataFrame\n    Y_pred_filtered = results_filtered['predicted'].values\n    '''\n    # Plot the training data, test data, and predicted values for the current unique_id\n    plt.figure(figsize=(15, 5))\n    plt.plot(train_filtered.index[-len(Y_train_filtered):], Y_train_filtered, label='Training Data')\n    plt.plot(test_filtered.index[:len(Y_test_filtered)], Y_test_filtered, label='Test Data')\n    plt.plot(results_filtered['date'][:len(Y_pred_filtered)], Y_pred_filtered, label='Predicted Values')\n    plt.title(f\"Time Series {unique_id}\")\n    plt.xlabel('Date')\n    plt.ylabel('Unit Sales')\n    plt.legend()\n    plt.show()\n    '''","metadata":{"papermill":{"duration":1.882769,"end_time":"2023-05-11T11:53:15.156985","exception":false,"start_time":"2023-05-11T11:53:13.274216","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-25T14:53:50.851530Z","iopub.status.idle":"2023-05-25T14:53:50.852098Z","shell.execute_reply.started":"2023-05-25T14:53:50.851823Z","shell.execute_reply":"2023-05-25T14:53:50.851849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation Metrics","metadata":{"papermill":{"duration":0.054478,"end_time":"2023-05-11T11:53:15.266497","exception":false,"start_time":"2023-05-11T11:53:15.212019","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error, mean_squared_error\n\ndef mean_absolute_scaled_error(actuals, predicted, seasonality=1):\n    mae = np.mean(np.abs(actuals - predicted))\n    naive_mae = np.mean(np.abs(actuals[seasonality:] - actuals[:-seasonality]))\n    return mae / naive_mae\n\nresults = []\n\n# Loop through each unique_id in the predictions_df\nfor unique_id in random_unique_ids:\n    unique_id_predictions = predictions_df[predictions_df['unique_id'] == unique_id]\n    actuals = unique_id_predictions['actuals'].values\n    predicted = unique_id_predictions['predicted'].values\n\n    # Calculate the error metrics\n    mae = mean_absolute_error(actuals, predicted)\n    rmse = np.sqrt(mean_squared_error(actuals, predicted))\n    mase = mean_absolute_scaled_error(actuals, predicted)\n\n    results.append({'unique_id': unique_id,\n                    'MAE': mae,\n                    'RMSE': rmse,\n                    'MASE': mase})\n\n# Save the results in a new DataFrame\nresults_df = pd.DataFrame(results)\n\nresults_df.to_csv('xgboost_metrics.csv', index=False)\n\nresults_df","metadata":{"papermill":{"duration":0.085811,"end_time":"2023-05-11T11:53:15.406802","exception":false,"start_time":"2023-05-11T11:53:15.320991","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-25T14:53:50.853644Z","iopub.status.idle":"2023-05-25T14:53:50.854202Z","shell.execute_reply.started":"2023-05-25T14:53:50.853913Z","shell.execute_reply":"2023-05-25T14:53:50.853936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.graph_objs as go\n\n# Create a box plot for MAE\ntrace1 = go.Box(\n    y=results_df['MAE'],\n    name=\"MAE\",\n    boxpoints='outliers',\n    jitter=0.3,\n    pointpos=0,\n    boxmean=True\n)\n\n# Create a box plot for RMSE\ntrace2 = go.Box(\n    y=results_df['RMSE'],\n    name=\"RMSE\",\n    boxpoints='outliers',\n    jitter=0.3,\n    pointpos=0,\n    boxmean=True\n)\n\n# Create a box plot for MASE\ntrace3 = go.Box(\n    y=results_df['MASE'],\n    name=\"MASE\",\n    boxpoints='outliers',\n    jitter=0.3,\n    pointpos=0,\n    boxmean=True\n)\n\n# Create a layout for the box plots\nlayout = go.Layout(\n    title=\"Evaluation Metrics Box Plots\",\n    yaxis=dict(title=\"Value\"),\n    boxmode='group'\n)\n\n# Combine the traces and layout into a single figure\nfig = go.Figure(data=[trace1, trace2, trace3], layout=layout)\n\n# Plot the figure\nfig.show()","metadata":{"papermill":{"duration":0.323579,"end_time":"2023-05-11T11:53:15.786619","exception":false,"start_time":"2023-05-11T11:53:15.463040","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-25T14:53:50.855857Z","iopub.status.idle":"2023-05-25T14:53:50.856357Z","shell.execute_reply.started":"2023-05-25T14:53:50.856103Z","shell.execute_reply":"2023-05-25T14:53:50.856125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compute the descriptive statistics for each metric\nmean_rmse = results_df['RMSE'].mean()\nmedian_rmse = results_df['RMSE'].median()\nstd_rmse = results_df['RMSE'].std()\nrange_rmse = results_df['RMSE'].max() - results_df['RMSE'].min()\n\nmean_mae = results_df['MAE'].mean()\nmedian_mae = results_df['MAE'].median()\nstd_mae = results_df['MAE'].std()\nrange_mae = results_df['MAE'].max() - results_df['MAE'].min()\n\nmean_mase = results_df['MASE'].mean()\nmedian_mase = results_df['MASE'].median()\nstd_mase = results_df['MASE'].std()\nrange_mase = results_df['MASE'].max() - results_df['MASE'].min()\n\n# Print the results\nprint(\"RMSE - Mean: {:.2f}, Median: {:.2f}, Standard Deviation: {:.2f}, Range: {:.2f}\".format(mean_rmse, median_rmse, std_rmse, range_rmse))\nprint(\"MAE - Mean: {:.2f}, Median: {:.2f}, Standard Deviation: {:.2f}, Range: {:.2f}\".format(mean_mae, median_mae, std_mae, range_mae))\nprint(\"MASE - Mean: {:.2f}, Median: {:.2f}, Standard Deviation: {:.2f}, Range: {:.2f}\".format(mean_mase, median_mase, std_mase, range_mase))","metadata":{"papermill":{"duration":0.073782,"end_time":"2023-05-11T11:53:15.915896","exception":false,"start_time":"2023-05-11T11:53:15.842114","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-25T14:53:50.858059Z","iopub.status.idle":"2023-05-25T14:53:50.858586Z","shell.execute_reply.started":"2023-05-25T14:53:50.858318Z","shell.execute_reply":"2023-05-25T14:53:50.858340Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Interpretability","metadata":{"papermill":{"duration":0.054635,"end_time":"2023-05-11T11:53:16.026177","exception":false,"start_time":"2023-05-11T11:53:15.971542","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Built-in Interpretability\n","metadata":{"papermill":{"duration":0.054773,"end_time":"2023-05-11T11:53:16.135655","exception":false,"start_time":"2023-05-11T11:53:16.080882","status":"completed"},"tags":[]}},{"cell_type":"code","source":"xgb.plot_importance(reg)\nplt.show()","metadata":{"papermill":{"duration":0.293393,"end_time":"2023-05-11T11:53:16.484742","exception":false,"start_time":"2023-05-11T11:53:16.191349","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-25T14:53:50.859802Z","iopub.status.idle":"2023-05-25T14:53:50.860335Z","shell.execute_reply.started":"2023-05-25T14:53:50.860066Z","shell.execute_reply":"2023-05-25T14:53:50.860089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SHAP\n","metadata":{"papermill":{"duration":0.055426,"end_time":"2023-05-11T11:53:16.595748","exception":false,"start_time":"2023-05-11T11:53:16.540322","status":"completed"},"tags":[]}},{"cell_type":"code","source":"pip install shap","metadata":{"execution":{"iopub.status.busy":"2023-05-25T14:53:50.861897Z","iopub.status.idle":"2023-05-25T14:53:50.862440Z","shell.execute_reply.started":"2023-05-25T14:53:50.862161Z","shell.execute_reply":"2023-05-25T14:53:50.862190Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shap\n\n# print the JS visualization code to the notebook\nshap.initjs()\n\n# Create a TreeExplainer object\nexplainer = shap.TreeExplainer(reg)\n\n# Calculate SHAP values\nshap_values = explainer.shap_values(X_all)\n\n# Plot SHAP summary plot\nshap.summary_plot(shap_values, X_all)","metadata":{"papermill":{"duration":12.755947,"end_time":"2023-05-11T11:53:29.409507","exception":false,"start_time":"2023-05-11T11:53:16.653560","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-25T14:53:50.864196Z","iopub.status.idle":"2023-05-25T14:53:50.864804Z","shell.execute_reply.started":"2023-05-25T14:53:50.864480Z","shell.execute_reply":"2023-05-25T14:53:50.864505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate SHAP values for the validation data\nexplainer = shap.TreeExplainer(reg)\nshap_values = explainer.shap_values(X_all)\n\n# Plot the SHAP summary plot\nshap.summary_plot(shap_values, X_all, plot_type=\"bar\")","metadata":{"papermill":{"duration":5.907941,"end_time":"2023-05-11T11:53:35.379308","exception":false,"start_time":"2023-05-11T11:53:29.471367","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-25T14:53:50.865945Z","iopub.status.idle":"2023-05-25T14:53:50.866477Z","shell.execute_reply.started":"2023-05-25T14:53:50.866201Z","shell.execute_reply":"2023-05-25T14:53:50.866225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"explainer = shap.TreeExplainer(reg)\nshap_values = explainer.shap_values(X_all)\n\n# visualize the first prediction's explanation\nshap.force_plot(explainer.expected_value, shap_values[0,:], X_all.iloc[0,:])","metadata":{"papermill":{"duration":5.612921,"end_time":"2023-05-11T11:53:41.054163","exception":false,"start_time":"2023-05-11T11:53:35.441242","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-25T14:53:50.868399Z","iopub.status.idle":"2023-05-25T14:53:50.869006Z","shell.execute_reply.started":"2023-05-25T14:53:50.868724Z","shell.execute_reply":"2023-05-25T14:53:50.868749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the number of samples to be visualized\nsample_size = 200\n\n# Randomly sample a subset of the dataset\nrandom_indices = np.random.choice(X_all.shape[0], size=sample_size, replace=False)\nX_sample = X_all.iloc[random_indices]\n\n# Compute the SHAP values for the sample\nshap_values_sample = explainer.shap_values(X_sample)\n\n# Create the force plot for the sampled dataset\nshap.force_plot(explainer.expected_value, shap_values_sample, X_sample)","metadata":{"papermill":{"duration":0.461585,"end_time":"2023-05-11T11:53:41.579908","exception":false,"start_time":"2023-05-11T11:53:41.118323","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-25T14:53:50.871091Z","iopub.status.idle":"2023-05-25T14:53:50.871692Z","shell.execute_reply.started":"2023-05-25T14:53:50.871361Z","shell.execute_reply":"2023-05-25T14:53:50.871385Z"},"trusted":true},"execution_count":null,"outputs":[]}]}